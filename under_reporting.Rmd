---
title: "Data completeness state"
author: "Dan Weinberger"
date: "4/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ExcessILI)
library(cdcfluview)
library(reshape2)
library(ggplot2)
library(lubridate)
library(RColorBrewer)
library(plotly)
library(MMWRweek)
library(readr)
library(rjson)
library(htmlTable)
library(RSocrata)
library(pdftools)
library(readr)
library(gsubfn)
library(INLA)
library (RCurl)


```
## Backfilling
#NOTE THE DATA ARE MISSING FOR JULY-OCT 2019

```{r}
#Data from Andrew: NOTE: it looks like July-oct 2019 is missing from these data
wk11 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data11.csv')
wk11$max.date.report <- as.Date('2020-03-14')
wk11$report.date <- as.Date('2020-03-27')

wk12 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data12.csv')
wk12$max.date.report <- as.Date('2020-03-21')
wk12$report.date <- as.Date('2020-04-03')

wk13 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data13.csv')
wk13$max.date.report <- as.Date('2020-03-28')
wk13$report.date <- as.Date('2020-04-10')

wk15 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data15.csv')
wk15$max.date.report <- as.Date('2020-04-11')
wk15$report.date <- as.Date('2020-04-17')

wk16 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data16.csv')
wk16$max.date.report <- as.Date('2020-04-18')
wk16$report.date <- as.Date('2020-04-24')

wk17 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data17.csv')
wk17$max.date.report <- as.Date('2020-04-25')
wk17$report.date <- as.Date('2020-05-01')

wk18 <- 
  read.csv('./archives_do_not_sync/State_Custom_Data18.csv')
wk18$max.date.report <- as.Date('2020-05-02')
wk18$report.date <- as.Date('2020-05-08')


all.reports <- rbind.data.frame(wk11,wk12,wk13,wk15, wk16, wk17)


all.reports$epiyr <-
  as.numeric(as.character(substr(all.reports$SEASON,1,4)))

all.reports$year <- all.reports$epiyr
all.reports$year[all.reports$WEEK<=26] <-
  all.reports$epiyr[all.reports$WEEK<=26] +1
all.reports$week.death <-
  mmwr_week_to_date(all.reports$year, all.reports$WEEK)+6

#Fix formatting for the count variables
all.reports$NUM.INFLUENZA.DEATHS <-
  gsub(',','',all.reports$NUM.INFLUENZA.DEATHS) 
all.reports$NUM.INFLUENZA.DEATHS <-  as.numeric(as.character(all.reports$NUM.INFLUENZA.DEATHS)) 

all.reports$NUM.PNEUMONIA.DEATHS <-
  gsub(',','',all.reports$NUM.PNEUMONIA.DEATHS) 
all.reports$NUM.PNEUMONIA.DEATHS <-  as.numeric(as.character(all.reports$NUM.PNEUMONIA.DEATHS)) 

all.reports$TOTAL.DEATHS <-
  gsub(',','',all.reports$TOTAL.DEATHS) 
all.reports$TOTAL.DEATHS <-  as.numeric(as.character(all.reports$TOTAL.DEATHS))

compare.m <- melt(all.reports[,c("week.death","SUB.AREA" ,"report.date","TOTAL.DEATHS" )], id.vars  =c("week.death",'SUB.AREA',"report.date"))

names(compare.m) <- 
  c('death_date','state','report_date','variable','N_deaths')

compare.m$report_date <-as.Date(compare.m$report_date)
compare.m$death_date <-as.Date(compare.m$death_date)

compare.m$complete.weeks <- round(as.vector(difftime(compare.m$report_date,
          compare.m$death_date, units='weeks')))
#compare.m$complete.weeks[compare.m$complete.weeks>5] <-5

compare.c <- dcast( compare.m[,c('death_date','state','report_date','N_deaths')], state+ death_date ~ report_date, value.var='N_deaths', fun.aggregate = mean)


new.reports <- compare.c
new.reports[,-c(1:2)] <- 
  apply(new.reports[,-c(1:2)],2, function(x){ 
    x[is.nan(x)] <- 0 
    return(x)
  
  })
new.reports2 <- new.reports
# count new reports
# for(i in 2:4){
# new.reports2[,(2+i)]  <-
#   new.reports[,(2+i)] - new.reports[,(2+i-1 )]
# }

new.reports2.m <- 
  melt(new.reports2, id.vars=c('state', 'death_date'))

names(new.reports2.m) <- c('state','death_date', 'report_date','N_new_reports')

new.reports2.m$death_date <- 
  as.Date( new.reports2.m$death_date)

new.reports2.m$report_date <- 
  as.Date( new.reports2.m$report_date)

new.reports2.m$time.report <-
  round(as.numeric(difftime(new.reports2.m$report_date,
     new.reports2.m$death_date,units='weeks') ))

new.reports2.m$time.report[new.reports2.m$time.report>=8] <- 8

new.reports2.m$time.report <-
  as.numeric(as.character(new.reports2.m$time.report))

#filter observations when report date is before death date
new.reports2.m <-
  new.reports2.m[(new.reports2.m$time.report > 0 & new.reports2.m$report_date>=as.Date('2020-04-25')) | (new.reports2.m$time.report > 1 & new.reports2.m$report_date<as.Date('2020-04-25')) 
                   ,] 

new.reports2.m <-
  new.reports2.m[new.reports2.m$time.report>0,] 

new.reports2.m$N_new_reports[new.reports2.m$N_new_reports<0] <- 0
```


## Set up reporting triangle
```{r}
#Ignore reports from first week
compare.m.alt <-   compare.m

#Filter if death date hasn't happened yet or happened a week ago
compare.m.alt <-
  compare.m.alt[as.numeric((compare.m.alt$report_date - compare.m.alt$death_date)) > 6,]


#Split by state and death date
compare.m.alt.spl <- 
  split(compare.m.alt, paste0(compare.m.alt$state,compare.m.alt$death_date)) 

#Sort by report date
compare.m.alt.spl <- 
  lapply(compare.m.alt.spl, function(x) x[order(x$report_date),])

#Subtract previous value to calculate new value
compare.m.alt.spl <- lapply(compare.m.alt.spl, function(x){
  
  #Remove rdundant rows if deaths was >6 months ago
  if(max(x$complete.weeks)>=26){
    x <-   x[1,]
    x$complete.weeks <-999
  }
#Combine first and second weeks of observation
  x$complete.weeks[x$complete.weeks==1] <-2
  
  x$new.reports <- x$N_deaths
      x$first.week.measured<-x$complete.weeks[1]

  if(nrow(x)>1){
    
    #If first observation we have for a week s after week 2, put in the 'most complete' column 999
    if(x$complete.weeks[1]>2){
      x$complete.weeks[1] <-999
      }
    
    for(i in 2:nrow(x)){
       x$new.reports[i]<-x$N_deaths[i]-x$N_deaths[(i-1)]
    }
  }
  return(x)
}) 

compare.m.alt.spl2 <-
  do.call(rbind.data.frame,compare.m.alt.spl)
#replace negative values with 0s
compare.m.alt.spl2$new.reports[compare.m.alt.spl2$new.reports<0] <-0

ds7 <- acast( compare.m.alt.spl2[,c('death_date','state','complete.weeks',"new.reports" )], state~ death_date ~ complete.weeks, value.var="new.reports" , fun.aggregate = sum)

ds7.length <- acast( compare.m.alt.spl2[,c('death_date','state','complete.weeks',"new.reports" )], state~ death_date ~ complete.weeks, value.var="new.reports" , fun.aggregate = length)

#If we don't have observation, set to NA
ds7[ds7.length==0] <-NA

compare.c.alt <- dcast( compare.m.alt.spl2[,c('death_date','state','complete.weeks',"new.reports" )], state+death_date + complete.weeks~., value.var="new.reports" , fun.aggregate = sum)
names(compare.c.alt) <-c('state', 'death_date','complete.weeks','new_reports')

#what is first week for which we have a report for each state? For dates where we don't have >26 weeks of data and don't observed the first week, we need to sum th eprobabilities (betas)
first.measured.date <- as.data.frame(unique(compare.m.alt.spl2[,c('death_date','first.week.measured')]))

max.measured <- max(first.measured.date$first.week.measured[first.measured.date$first.week.measured!=999])

first.measured.date$first.week.measured[first.measured.date$first.week.measured==999] <- max.measured+1

#get rid of columns where we don't have a meausurement
ds7 <- ds7[,,c(1:max.measured, dim(ds7)[3])]
```


## Param 1: model the new cases
```{r}
model_string_alt<-
"model
{
  # Likelihood
  for( t in 1:n.dates ){
  for(d in 1:(D+1)){
  
  n[t,d] ~ dpois(lambda[t,d])
  
  log(lambda[t,d]) <- (int +     
            beta.logged2[d]*step(D-d) +
            sum.beta.logged2[t]*(1-step(D-d)) +
                    sin26[t]*delta[1] +
                    cos26[t]*delta[2] +
                    sin52[t]*delta[3] +
                    cos52[t]*delta[4] +
                    phi[t] 
                    ) 
  }
    log(expected[t])<- 
        (int +      sin26[t]*delta[1] +
                    cos26[t]*delta[2] +
                    sin52[t]*delta[3] +
                    cos52[t]*delta[4] +
                    phi[t] 
           )
    log(baseline[t])<- 
        (int +      sin26[t]*delta[1] +
                    cos26[t]*delta[2] +
                    sin52[t]*delta[3] +
                    cos52[t]*delta[4] 
           )
  sum.n[t] ~ dpois(expected[t])
  sum.lambda[t] <- expected[t]
  }

   #AR1 Random Effect
  phi[1] ~ dnorm(alpha1.mean.prior, alpha1.prec.prior)
  for(t in 2:n.dates){
     phi[t] ~ dnorm(phi[t-1],tau2.alpha)
  }
     
     
   ##  
  int~dnorm(0, 1e-2)

  ## Prior for beta
  beta.logged <- log(beta)
  beta.logged2 <- c(beta.logged,0)
  beta ~ ddirch(beta.priors)
  
  for( t in 1:n.dates ){
    sum.beta[t] <- sum(beta[1:N.first.obs[t]])
    sum.beta.logged2[t] <- log(sum.beta[t])
  }

  # Prior for variance
  tau2.alpha ~ dgamma(alphat.shape.prior,alphat.rate.prior)
  
  for(i in 1:4){
    delta[i] ~ dnorm(0,1e-2)
  }
}
"


```

```{r}

st1 <- ds7['Louisiana',,]
date.sum <- apply(st1,1,sum, na.rm=T) #total observations for 
death_date <- as.Date(dimnames(st1)[[1]])

st2 <- st1[, -ncol(st1)] #remove column '99'
week.index <- as.numeric(difftime(death_date, min(death_date), units='week'))
sin52 <- sin(2*pi*week.index/52.1775)
cos52 <- cos(2*pi*week.index/52.1775)

sin26 <- sin(2*pi*week.index*2/52.1775)
cos26 <- cos(2*pi*week.index*2/52.1775)

beta.priors <- rep(1, times=(ncol(st2)))

reporting.triangle <- st1

reporting.triangle[reporting.triangle[,1]>0, ncol(reporting.triangle)] <-NA

max_D <- ncol(reporting.triangle)-1


library(rjags)
library(HDInterval)
##############################################################
#Model Fitting
##############################################################
inits1=list(".RNG.seed"=c(123), ".RNG.name"='base::Wichmann-Hill')
inits2=list(".RNG.seed"=c(456), ".RNG.name"='base::Wichmann-Hill')
inits3=list(".RNG.seed"=c(789), ".RNG.name"='base::Wichmann-Hill')


##############################################
#Model Organization
##############################################
model_spec<-textConnection(model_string_alt)
model_jags<-jags.model(model_spec, 
                       inits=list(inits1,inits2, inits3),
                       data=list('n.dates' =
                                   nrow(reporting.triangle),
                                 'n' = reporting.triangle,
                                 'D' = ncol(reporting.triangle)-1,
                                 'sin52'=sin52,
                                 'sin26'=sin26,
                                 'cos52'=cos52,
                                 'cos26'=cos26,
                                 alphat.shape.prior=0.001,
                                alphat.rate.prior=0.001,
                                alpha1.mean.prior=0,
                                alpha1.prec.prior=0.001,
                'N.first.obs'=(first.measured.date$first.week.measured-1),
                           'beta.priors'=beta.priors
                                 
                                 ),
                       n.adapt=4000, 
                       n.chains=3)

params<-c('sum.n','sum.lambda',
          'beta.logged', 'alpha', 'phi', 'baseline')

##############################################
#Posterior Sampling
##############################################
posterior_samples<-coda.samples(model_jags, 
                                params, 
                                n.iter=5000)
posterior_samples.all<-do.call(rbind,posterior_samples)
#post1.summary<-summary(posterior_samples)
#post_means<-colMeans(posterior_samples.all)
post_means<-apply(posterior_samples.all, 2, median)
sample.labs<-names(post_means)
ci<-t(hdi(posterior_samples.all, credMass = 0.95))
ci<-matrix(sprintf("%.1f",round(ci,1)), ncol=2)
row.names(ci)<-sample.labs
post_means<-sprintf("%.1f",round(post_means,1))
names(post_means)<-sample.labs

pred.index <- grep('sum.lambda',sample.labs)
pred.index2 <- grep('sum.n',sample.labs)

beta.index <- grep('beta.logged',sample.labs)
alpha.index <- grep('alpha',sample.labs)
baseline.index <- grep('baseline',sample.labs)
phi.index <- grep('phi',sample.labs)

pred.means <- post_means[pred.index2]
beta.log.means <- as.numeric(post_means[beta.index])
probs <- exp(beta.log.means)

alpha <- as.numeric(post_means[alpha.index])

baseline <- as.numeric(post_means[baseline.index])

phi <- as.numeric(post_means[phi.index])

pred.ci <- ci[pred.index2,]
all.preds<- as.numeric(as.character(cbind(pred.means, pred.ci)))
all.preds<- matrix(all.preds,ncol=3)
matplot(all.preds[350:ncol(all.preds),], type='l', lty=c(1,2,2), col=c('black','gray','gray'))
points(date.sum[350:ncol(all.preds)], type='p',pch=16 ,col='red')
```

#US national data
```{r}

```

